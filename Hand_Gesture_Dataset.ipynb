{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPZ2DOzF3yLgT9DQLRbHPVd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fcyifun55RBX","executionInfo":{"status":"ok","timestamp":1745818634391,"user_tz":-330,"elapsed":37858,"user":{"displayName":"Chilaka Bala Muneendra","userId":"14694632565050296207"}},"outputId":"3e5f43ec-41c5-43bf-9b2b-36bbb38aa0f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Synthetic dataset created at: /content/hand_gesture_dataset\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 347ms/step - accuracy: 0.3522 - loss: 1.1244 - val_accuracy: 0.3000 - val_loss: 1.1134\n","Epoch 2/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - accuracy: 0.3564 - loss: 1.1124 - val_accuracy: 0.3000 - val_loss: 1.1038\n","Epoch 3/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.2860 - loss: 1.1132 - val_accuracy: 0.3000 - val_loss: 1.1126\n","Epoch 4/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.3621 - loss: 1.1013 - val_accuracy: 0.3000 - val_loss: 1.1011\n","Epoch 5/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.2798 - loss: 1.1020 - val_accuracy: 0.3000 - val_loss: 1.0994\n","Epoch 6/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.4748 - loss: 1.0942 - val_accuracy: 0.3000 - val_loss: 1.1049\n","Epoch 7/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.3326 - loss: 1.1069 - val_accuracy: 0.3000 - val_loss: 1.1070\n","Epoch 8/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.3309 - loss: 1.1038 - val_accuracy: 0.3000 - val_loss: 1.1023\n","Epoch 9/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.3267 - loss: 1.1010 - val_accuracy: 0.2667 - val_loss: 1.0992\n","Epoch 10/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - accuracy: 0.2988 - loss: 1.0992 - val_accuracy: 0.3333 - val_loss: 1.0989\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.3333 - loss: 1.0989\n","Test Accuracy: 33.33%\n","Model saved as 'hand_gesture_model.keras'\n"]}],"source":["import os\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","\n","# Step 1: Create a Synthetic Dataset (if no dataset exists)\n","def create_synthetic_dataset(base_dir='hand_gesture_dataset', image_size=(64, 64), num_classes=3, num_images_per_class=50):\n","    os.makedirs(base_dir, exist_ok=True)\n","    class_names = [f'class_{i}' for i in range(num_classes)]\n","    for class_name in class_names:\n","        class_dir = os.path.join(base_dir, class_name)\n","        os.makedirs(class_dir, exist_ok=True)\n","        for i in range(num_images_per_class):\n","            random_image = np.random.randint(0, 256, (image_size[0], image_size[1], 3), dtype=np.uint8)\n","            img = Image.fromarray(random_image)\n","            img.save(os.path.join(class_dir, f'{class_name}_{i}.jpg'))\n","    print(f\"Synthetic dataset created at: {os.path.abspath(base_dir)}\")\n","    return class_names\n","\n","# Step 2: Load the Dataset\n","def load_images_from_folder(folder, image_size=(64, 64)):\n","    images = []\n","    labels = []\n","    class_names = os.listdir(folder)\n","    for label, class_name in enumerate(class_names):\n","        class_folder = os.path.join(folder, class_name)\n","        for filename in os.listdir(class_folder):\n","            if filename.endswith('.jpg') or filename.endswith('.png'):\n","                img_path = os.path.join(class_folder, filename)\n","                img = Image.open(img_path).resize(image_size)\n","                images.append(np.array(img))\n","                labels.append(label)\n","    return np.array(images), np.array(labels), class_names\n","\n","# Step 3: Define the CNN Model\n","def build_cnn_model(input_shape, num_classes):\n","    model = Sequential([\n","        Input(shape=input_shape),\n","        Conv2D(32, (3, 3), activation='relu'),\n","        MaxPooling2D((2, 2)),\n","        Conv2D(64, (3, 3), activation='relu'),\n","        MaxPooling2D((2, 2)),\n","        Conv2D(128, (3, 3), activation='relu'),\n","        MaxPooling2D((2, 2)),\n","        Flatten(),\n","        Dense(128, activation='relu'),\n","        Dropout(0.5),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Step 4: Main Script\n","if __name__ == \"__main__\":\n","    # Dataset parameters\n","    dataset_path = 'hand_gesture_dataset'\n","    image_size = (64, 64)\n","\n","    # Create synthetic dataset if it doesn't exist\n","    if not os.path.exists(dataset_path):\n","        class_names = create_synthetic_dataset(base_dir=dataset_path, image_size=image_size, num_classes=3, num_images_per_class=50)\n","    else:\n","        class_names = os.listdir(dataset_path)\n","\n","    # Load the dataset\n","    X, y, class_names = load_images_from_folder(dataset_path, image_size=image_size)\n","    X = X / 255.0  # Normalize pixel values to [0, 1]\n","    y = to_categorical(y, num_classes=len(class_names))  # One-hot encode labels\n","\n","    # Split the dataset into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Data Augmentation\n","    datagen = ImageDataGenerator(\n","        rotation_range=20,\n","        width_shift_range=0.2,\n","        height_shift_range=0.2,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True,\n","        fill_mode='nearest'\n","    )\n","    datagen.fit(X_train)\n","\n","    # Build the CNN model\n","    model = build_cnn_model(input_shape=(image_size[0], image_size[1], 3), num_classes=len(class_names))\n","\n","    # Train the model\n","    model.fit(datagen.flow(X_train, y_train, batch_size=16), epochs=10, validation_data=(X_test, y_test))\n","\n","    # Evaluate the model\n","    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n","\n","    # Save the model\n","    model.save('hand_gesture_model.keras')\n","    print(\"Model saved as 'hand_gesture_model.keras'\")"]}]}